from google.colab import drive
drive.mount('/content/drive')

import os, torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

base_dir = "/content/drive/MyDrive/DIV2K"
train_dir = os.path.join(base_dir, "train")
valid_dir = os.path.join(base_dir, "valid")
test_dir  = os.path.join(base_dir, "test")
save_dir  = "/content/drive/MyDrive/SR_outputs"
os.makedirs(save_dir, exist_ok=True)

class SRDataset(Dataset):
    def __init__(self, root, crop_size=64, upscale_factor=2):
        self.root = root
        self.files = [f for f in os.listdir(root) if f.lower().endswith((".png",".jpg",".jpeg"))]
        self.crop = transforms.CenterCrop(crop_size)
        self.to_tensor = transforms.ToTensor()
        self.down = transforms.Resize(crop_size//upscale_factor, interpolation=Image.BICUBIC)
        self.up   = transforms.Resize(crop_size, interpolation=Image.BICUBIC)
    def __len__(self):
        return len(self.files)
    def __getitem__(self, i):
        p = os.path.join(self.root, self.files[i])
        img = Image.open(p).convert("RGB")
        x_hr = self.crop(img)
        y_lr = self.up(self.down(self.crop(img)))
        return self.to_tensor(y_lr), self.to_tensor(x_hr)

train_set = SRDataset(train_dir, crop_size=64, upscale_factor=2)
valid_set = SRDataset(valid_dir, crop_size=64, upscale_factor=2)
test_set  = SRDataset(test_dir,  crop_size=64, upscale_factor=2)

train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)
valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)
test_loader  = DataLoader(test_set,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)

class SRCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.relu = nn.ReLU(inplace=True)
        self.c1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)
        self.c2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)
        self.c3 = nn.Conv2d(32, 3, kernel_size=5, stride=1, padding=2)
    def forward(self, x):
        x = self.relu(self.c1(x))
        x = self.relu(self.c2(x))
        x = self.c3(x)
        return x

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SRCNN().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

epochs = 50
for epoch in range(epochs):
    model.train()
    tot = 0.0
    for y, x in train_loader:
        y = y.to(device, non_blocking=True)
        x = x.to(device, non_blocking=True)
        pred = model(y)
        loss = criterion(pred, x)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        tot += loss.item()
    model.eval()
    with torch.no_grad():
        vtot = 0.0
        for yv, xv in valid_loader:
            yv = yv.to(device, non_blocking=True)
            xv = xv.to(device, non_blocking=True)
            pv = model(yv)
            vtot += criterion(pv, xv).item()
    print(f"{epoch+1}/{epochs} train_loss={tot/len(train_loader):.6f} valid_loss={vtot/len(valid_loader):.6f}")

ckpt_path = "/content/drive/MyDrive/srcnn_checkpoint.pth"
torch.save(model.state_dict(), ckpt_path)

model2 = SRCNN().to(device)
model2.load_state_dict(torch.load(ckpt_path, map_location=device))
model2.eval()

to_pil = transforms.ToPILImage()
idx = 0
with torch.no_grad():
    for yb, _ in test_loader:
        yb = yb.to(device, non_blocking=True)
        pb = model2(yb).clamp(0,1).cpu()
        for i in range(pb.size(0)):
            img = to_pil(pb[i])
            name = f"sr_{idx:04d}.png"
            img.save(os.path.join(save_dir, name))
            idx += 1